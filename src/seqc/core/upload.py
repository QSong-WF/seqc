import os
import pandas as pd
from seqc import io, remote, log


def update_directories_for_aws(output_stem: str, output_prefix: str) -> (
        str, str, str, str):
    """
    if the --aws argument is passed, this function returns updated directories and
     prefixes for output files

    :param output_stem: str, stem for output files
    :param output_prefix: str, prefix for output files
    :returns output_stem, output_dir, output_prefix: (str, str, str), stem, directory and
     prefix for output files generated by an aws SEQC run.
    """

    aws_upload_key = output_stem
    if not aws_upload_key.endswith('/'):
        aws_upload_key += '/'
    output_stem = '/data/' + output_prefix
    output_dir, output_prefix = os.path.split(output_stem)
    return aws_upload_key, output_stem, output_dir, output_prefix


def data_and_notify(
        email_status: str, aws_upload_key: str, align: bool, input_data: str,
        manage_merged: io.ProcessManager, process_samfile: bool,
        merged_fastq: str, samfile: str, read_array: str,
        sparse_proc: io.ProcessManager, sparse_csv: str,
        manage_ra: io.ProcessManager, summary: dict, fastq_records: int,
        sam_records: int, total_molecules: int, mols_lost: int, cells_lost: int,
        manage_samfile: io.ProcessManager, cell_description: pd.Series,
        output_stem: str, log_name: str, email: bool) -> None:
    """
    Uploads data and notifies the user of the termination of a run

    :param email_status: str, email address to email results
    :param aws_upload_key: str, location to upload files on aws
    :param align: bool, whether or not alignment occurred
    :param input_data: str, indicator, stores the type of input data
    :param manage_merged: io.ProcessManager, an upload manager for merged_fastq
    :param process_samfile: bool, whether or not samfile was processed
    :param merged_fastq: str, name of merged fastq file
    :param samfile: str, name of sam file
    :param read_array: str, name of stored ReadArray
    :param sparse_proc: io.ProcessManager, an upload manager for sparse counts file
    :param sparse_csv: str, name of sparse_csv file
    :param manage_ra: io.ProcessManager, an upload manager for the ReadArray
    :param summary: dict, object containing summary statistics
    :param fastq_records: int, number of processed fastq records
    :param sam_records: int, number of processed sam records
    :param total_molecules: int, number of molecules
    :param mols_lost: int, number of molecules lost
    :param cells_lost: int, number of cells lost
    :param manage_samfile: io.ProcessManager, an upload manager for the sam file
    :param cell_description: pd.Series, a summary of cells and cell counts
    :param output_stem: str, stem for file output
    :param log_name: str, name of SEQC.log file
    :param email: bool, whether email should be sent
    :return None:
    """

    log.info('Starting file upload onto %s.' % aws_upload_key)

    if email_status and aws_upload_key is not None:
        # make sure that all other files are uploaded before termination
        if align and input_data != 'merged':
            if manage_merged:
                manage_merged.wait_until_complete()
                log.info('Successfully uploaded %s to the specified S3 location "%s"' %
                         (merged_fastq, aws_upload_key))
        if process_samfile:
            if input_data != 'samfile':
                if manage_samfile:
                    manage_samfile.wait_until_complete()
                    log.info('Successfully uploaded %s to the specified S3 location "%s"'
                             % (samfile, aws_upload_key))
            if manage_ra:
                manage_ra.wait_until_complete()
                log.info('Successfully uploaded %s to the specified S3 location "%s"' %
                         (read_array, aws_upload_key))
            sparse_proc.wait_until_complete()
            log.info('Successfully uploaded %s to the specified S3 location "%s"' %
                     (sparse_csv + '.gz', aws_upload_key))

        # upload count matrix and alignment summary at the very end
        if summary:
            if fastq_records:
                summary['n_fastq'] = fastq_records
            else:
                summary['n_fastq'] = 'NA'
            if sam_records:
                summary['n_sam'] = sam_records
            else:
                summary['n_sam'] = 'NA'
            summary['total_mc'] = total_molecules
            summary['mols_lost'] = mols_lost
            summary['cells_lost'] = cells_lost
            summary['cell_desc'] = cell_description

        # todo: run summary will not be reported if n_fastq or n_sam = NA
        remote.upload_results(
            output_stem, email_status, aws_upload_key, input_data,
            summary, log_name, email)
